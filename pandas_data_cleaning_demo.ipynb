{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded! Shape: 901 rows x 12 columns\n"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset from a public URL\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Inject some intentional messiness for the demo\n",
    "# Add duplicate rows\n",
    "df = pd.concat([df, df.iloc[0:10]], ignore_index=True)\n",
    "\n",
    "# Add inconsistent string values in 'Sex' column\n",
    "df.loc[5, 'Sex'] = 'Male'   # should be lowercase 'male'\n",
    "df.loc[9, 'Sex'] = 'FEMALE' # should be lowercase 'female'\n",
    "\n",
    "# Replace some valid Ages with a sentinel value used as 'unknown'\n",
    "df.loc[df.sample(200, random_state=42).index, 'Age'] = -1\n",
    "\n",
    "print(f\"Dataset loaded! Shape: {df.shape[0]} rows x {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ea319",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .head() - Preview the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .info() - Column data types and missing value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .describe() - Summary statistics for numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a584e",
   "metadata": {},
   "source": [
    "## Step 3: Handling Missing Values\n",
    "\n",
    "\n",
    "### 3a. Count Missing Values\n",
    "\n",
    "`.isna().sum()` counts the number of `NaN` values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values per column .isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See missing values as a percentage of total rows\n",
    "# missing_pct = (df.isna().sum() / len(df) * 100).round(2)\n",
    "# print(\"Missing values as % of total rows:\")\n",
    "# print(missing_pct[missing_pct > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Drop Columns with Too Many Missing Values\n",
    "\n",
    "`.drop()` removes a column (use `axis=1` for columns, `axis=0` for rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Cabin' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Drop Rows with Missing Values\n",
    "\n",
    "`.dropna()` removes **rows** containing any `NaN` values. Use this when missing data is rare and you can afford to lose those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'Embarked' column only has 2 missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Fill Missing Values with `.fillna()`\n",
    "\n",
    "Instead of dropping rows, we can **fill** missing values with a sensible substitute:\n",
    "\n",
    "- **Mean**: good for normally distributed numeric data\n",
    "- **Median**: better for skewed distributions (less sensitive to outliers)\n",
    "- **Mode**: best for categorical data (most frequent value)\n",
    "- **A constant**: when you have domain knowledge about a good default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'Age' values with the MEDIAN age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all missing values are handled\n",
    "# remaining_missing = df.isna().sum()\n",
    "# print(\"Remaining missing values:\")\n",
    "# print(remaining_missing[remaining_missing > 0])\n",
    "\n",
    "# if remaining_missing.sum() == 0:\n",
    "#     print(\"\\n No missing values remaining!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Handling Duplicates\n",
    "\n",
    "### 4a. Detect Duplicates\n",
    "\n",
    "`.duplicated()` returns a boolean Series — `True` for rows that are exact duplicates of an earlier row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "09e56a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Remove Duplicates\n",
    "\n",
    "`.drop_duplicates()` keeps the first occurrence of each duplicate row and removes the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Replacing Values\n",
    "\n",
    "`.replace()` lets us swap specific values with correct ones.\n",
    "\n",
    "### 5a. Fix Inconsistent String Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the 'Sex' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix casing inconsistencies using .str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Replace Invalid Numeric Values\n",
    "\n",
    "We injected `-1` as a sentinel for \"unknown age\". Negative ages are impossible, so we replace them with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative ages\n",
    "\n",
    "# Replace -1 with median age using .replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c. Standardize Categorical Labels\n",
    "\n",
    "Let's also make the `Survived` columns more readable by mapping numeric codes to descriptive labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0/1 in Survived with descriptive labels\n",
    "\n",
    "# Preview the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Summary of Cleaned Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final overview of cleaned data\n",
    "# print(\"=== CLEANED DATASET SUMMARY ===\")\n",
    "# print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "# print(f\"Missing values: {df.isna().sum().sum()}\")\n",
    "# print(f\"Duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first few rows of the cleaned data\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  What we cleaned:\n",
    "\n",
    "| Problem | How We Fixed It |\n",
    "|---|---|\n",
    "| `Cabin` had >70% missing values | Dropped the entire column |\n",
    "| `Embarked` had 2 missing rows | Dropped those rows |\n",
    "| `Age` had many missing values | Filled with median age |\n",
    "| 10 duplicate rows | Removed with `.drop_duplicates()` |\n",
    "| `Sex` had uppercase variants | Standardized to lowercase |\n",
    "| `Age` had -1 sentinel values | Replaced with median age |\n",
    "| Numeric codes in `Survived`/`Pclass` | Replaced with readable labels |\n",
    "\n",
    "\n",
    "---\n",
    "##  Hands-On Exercises\n",
    "\n",
    "Now it's your turn! Try the following exercises to practice what you've learned.\n",
    "\n",
    "> **Tip**: Work on a copy of the cleaned DataFrame: `df_exercise = df.copy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise DataFrame ready! Missing values:\n",
      "Age         149\n",
      "Fare         30\n",
      "Cabin       694\n",
      "Embarked      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make a copy to experiment with\n",
    "df_exercise = df.copy()\n",
    "\n",
    "# Manually reintroduce some NaN values for practice\n",
    "import random\n",
    "random.seed(42)\n",
    "nan_indices = random.sample(range(len(df_exercise)), 30)\n",
    "df_exercise.loc[nan_indices, 'Fare'] = np.nan\n",
    "df_exercise.loc[nan_indices[:15], 'Age'] = np.nan\n",
    "\n",
    "print(\"Exercise DataFrame ready! Missing values:\")\n",
    "print(df_exercise.isna().sum()[df_exercise.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Fill Missing `Fare` Values with the Mean\n",
    "\n",
    "The `Fare` column now has some missing values. Fill them using the **mean** fare price.\n",
    "\n",
    "*Hint: Use `df_exercise['Fare'].mean()` and `.fillna()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Your code here:\n",
    "\n",
    "# mean_fare = ...\n",
    "# df_exercise['Fare'] = ...\n",
    "\n",
    "# Check your answer:\n",
    "# print(f\"Missing Fare values: {df_exercise['Fare'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Fill Missing `Age` Values with the Mode\n",
    "\n",
    "Instead of using the median, try using the **mode** (most common value) to fill missing ages.\n",
    "\n",
    "*Hint: Use `df_exercise['Age'].mode()[0]` to get the mode value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "# mode_age = ...\n",
    "# df_exercise['Age'] = ...\n",
    "\n",
    "# Check:\n",
    "# print(f\"Missing Age values: {df_exercise['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Drop a Column\n",
    "\n",
    "The `Ticket` column contains ticket numbers that aren't useful for most analyses. Drop it from `df_exercise`.\n",
    "\n",
    "*Hint: Use `.drop(columns=[...])`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "# df_exercise = ...\n",
    "\n",
    "# Check:\n",
    "# print(df_exercise.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Replace Values in `Embarked`\n",
    "\n",
    "The `Embarked` column contains codes: `'S'`, `'C'`, `'Q'`. Replace them with the full port names:\n",
    "- `'S'` → `'Southampton'`\n",
    "- `'C'` → `'Cherbourg'`\n",
    "- `'Q'` → `'Queenstown'`\n",
    "\n",
    "*Hint: Use `.replace({...})` with a dictionary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n",
    "# df_exercise['Embarked'] = ...\n",
    "\n",
    "# Check:\n",
    "# print(df_exercise['Embarked'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Best Practices for Data Cleaning in Pandas\n",
    "\n",
    "Here's a summary of what you should always keep in mind:\n",
    "\n",
    "1. **Always inspect your data first** — use `.head()`, `.info()`, and `.describe()` before touching anything.\n",
    "\n",
    "2. **Never modify the original dataset** — work on a copy (`df = raw_df.copy()`) so you can start over if needed.\n",
    "\n",
    "3. **Understand *why* data is missing** — missing data can be Missing At Random (MAR), Missing Completely At Random (MCAR), or Missing Not At Random (MNAR). The cause should guide your strategy.\n",
    "\n",
    "4. **Drop columns > ~60–70% missing** — they rarely provide useful signal.\n",
    "\n",
    "5. **Use median over mean for skewed data** — mean is sensitive to outliers; median is more robust.\n",
    "\n",
    "6. **Always check for duplicates** — especially after merging datasets.\n",
    "\n",
    "7. **Standardize strings early** — lowercase everything with `.str.lower()` to avoid case-mismatch bugs.\n",
    "\n",
    "8. **Validate after every step** — recheck `.isna().sum()` and `.duplicated().sum()` frequently.\n",
    "\n",
    "9. **Document your decisions** — keep notes (like these Markdown cells!) explaining *why* you made each cleaning choice.\n",
    "\n",
    "10. **Data cleaning is iterative** — you'll often discover new issues mid-analysis. That's normal!\n",
    "\n",
    "---\n",
    "\n",
    " **Congratulations — you've completed the Pandas Data Cleaning!**\n",
    "\n",
    "For further learning, explore:\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [Kaggle Learn: Pandas](https://www.kaggle.com/learn/pandas)\n",
    "- [Real Python: Pandas Data Cleaning](https://realpython.com/python-data-cleaning-numpy-pandas/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
